{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üìä NEWS2 Calculation Benchmark: Model Comparison\n",
                "\n",
                "**Head-to-Head: NurseSim-Triage vs Gemini 3 vs GPT-4o**\n",
                "\n",
                "Testing which model most accurately calculates NEWS2 scores from vital signs.\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -q gradio_client google-generativeai openai pandas matplotlib"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import json, re, time\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from dataclasses import dataclass\n",
                "from typing import Dict\n",
                "from gradio_client import Client\n",
                "import google.generativeai as genai\n",
                "import openai\n",
                "from google.colab import userdata\n",
                "\n",
                "# API Setup\n",
                "openai.api_key = userdata.get('OPENAI_API_KEY')\n",
                "genai.configure(api_key=userdata.get('GOOGLE_API_KEY'))\n",
                "\n",
                "print(\"‚úÖ Setup complete\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Gold Standard NEWS2 Calculator\n",
                "def calculate_news2(rr, spo2, on_oxygen, sbp, hr, temp, avpu):\n",
                "    scores = {}\n",
                "    \n",
                "    # RR\n",
                "    if rr <= 8: scores['rr'] = 3\n",
                "    elif rr <= 11: scores['rr'] = 1\n",
                "    elif rr <= 20: scores['rr'] = 0\n",
                "    elif rr <= 24: scores['rr'] = 2\n",
                "    else: scores['rr'] = 3\n",
                "    \n",
                "    # SpO2 (Scale 1)\n",
                "    if spo2 <= 91: scores['spo2'] = 3\n",
                "    elif spo2 <= 93: scores['spo2'] = 2\n",
                "    elif spo2 <= 95: scores['spo2'] = 1\n",
                "    else: scores['spo2'] = 0\n",
                "    \n",
                "    scores['air_o2'] = 2 if on_oxygen else 0\n",
                "    \n",
                "    # SBP\n",
                "    if sbp <= 90: scores['sbp'] = 3\n",
                "    elif sbp <= 100: scores['sbp'] = 2\n",
                "    elif sbp <= 110: scores['sbp'] = 1\n",
                "    elif sbp <= 219: scores['sbp'] = 0\n",
                "    else: scores['sbp'] = 3\n",
                "    \n",
                "    # HR\n",
                "    if hr <= 40: scores['hr'] = 3\n",
                "    elif hr <= 50: scores['hr'] = 1\n",
                "    elif hr <= 90: scores['hr'] = 0\n",
                "    elif hr <= 110: scores['hr'] = 1\n",
                "    elif hr <= 130: scores['hr'] = 2\n",
                "    else: scores['hr'] = 3\n",
                "    \n",
                "    # Temp\n",
                "    if temp <= 35.0: scores['temp'] = 3\n",
                "    elif temp <= 36.0: scores['temp'] = 1\n",
                "    elif temp <= 38.0: scores['temp'] = 0\n",
                "    elif temp <= 39.0: scores['temp'] = 1\n",
                "    else: scores['temp'] = 2\n",
                "    \n",
                "    scores['avpu'] = 0 if avpu.upper() == 'A' else 3\n",
                "    \n",
                "    return sum(scores.values())\n",
                "\n",
                "print(\"‚úÖ Gold standard calculator ready\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test Cases\n",
                "@dataclass\n",
                "class TestCase:\n",
                "    id: str\n",
                "    desc: str\n",
                "    rr: int\n",
                "    spo2: int\n",
                "    o2: bool\n",
                "    sbp: int\n",
                "    hr: int\n",
                "    temp: float\n",
                "    avpu: str\n",
                "\n",
                "TESTS = [\n",
                "    TestCase(\"LOW_01\", \"Stable\", 14, 98, False, 125, 72, 36.8, \"A\"),\n",
                "    TestCase(\"LOW_02\", \"Mild tachycardia\", 16, 97, False, 130, 95, 37.2, \"A\"),\n",
                "    TestCase(\"LOW_03\", \"Post-op fever\", 18, 96, False, 118, 88, 38.5, \"A\"),\n",
                "    TestCase(\"MED_01\", \"Hypoxia + tachy\", 20, 94, False, 115, 105, 37.0, \"A\"),\n",
                "    TestCase(\"MED_02\", \"On O2 + tachypnoea\", 22, 95, True, 120, 85, 37.5, \"A\"),\n",
                "    TestCase(\"MED_03\", \"Sepsis screen\", 24, 92, True, 95, 115, 38.8, \"A\"),\n",
                "    TestCase(\"MED_04\", \"Hypotensive\", 20, 96, False, 88, 125, 37.2, \"A\"),\n",
                "    TestCase(\"HIGH_01\", \"Severe sepsis\", 28, 88, True, 82, 135, 39.5, \"V\"),\n",
                "    TestCase(\"HIGH_02\", \"Resp failure\", 32, 85, True, 90, 120, 38.0, \"A\"),\n",
                "    TestCase(\"HIGH_03\", \"Altered GCS\", 18, 96, False, 130, 80, 37.0, \"V\"),\n",
                "    TestCase(\"EDGE_01\", \"Bradycardia\", 12, 99, False, 140, 42, 36.5, \"A\"),\n",
                "    TestCase(\"EDGE_02\", \"Hypothermia\", 14, 97, False, 100, 55, 34.5, \"A\"),\n",
                "    TestCase(\"EDGE_03\", \"HTN crisis\", 16, 98, False, 225, 90, 37.0, \"A\"),\n",
                "]\n",
                "\n",
                "# Add expected scores\n",
                "for t in TESTS:\n",
                "    t.expected = calculate_news2(t.rr, t.spo2, t.o2, t.sbp, t.hr, t.temp, t.avpu)\n",
                "\n",
                "print(f\"‚úÖ {len(TESTS)} test cases\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ü§ñ Model Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. NurseSim-Triage (your model via HF Space)\n",
                "print(\"Connecting to NurseSim-Triage HF Space...\")\n",
                "try:\n",
                "    nursesim_client = Client(\"NurseCitizenDeveloper/NurseSim-Triage-Demo\")\n",
                "    print(\"‚úÖ NurseSim-Triage connected\")\n",
                "except Exception as e:\n",
                "    print(f\"‚ö†Ô∏è NurseSim connection failed: {e}\")\n",
                "    nursesim_client = None"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2. Gemini 3\n",
                "GEMINI_MODELS = ['gemini-3-pro', 'gemini-3', 'gemini-2.0-flash-exp']\n",
                "gemini_model = None\n",
                "gemini_name = None\n",
                "for m in GEMINI_MODELS:\n",
                "    try:\n",
                "        gemini_model = genai.GenerativeModel(m)\n",
                "        gemini_model.generate_content(\"test\")\n",
                "        gemini_name = m\n",
                "        print(f\"‚úÖ Gemini: {m}\")\n",
                "        break\n",
                "    except:\n",
                "        continue\n",
                "\n",
                "# 3. GPT-4o\n",
                "gpt_client = openai.OpenAI()\n",
                "print(\"‚úÖ GPT-4o ready\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Query functions\n",
                "NEWS2_PROMPT = \"\"\"Calculate NEWS2 score for these vitals. Return ONLY the total score as a number.\n",
                "RR: {rr}, SpO2: {spo2}%, On O2: {o2}, SBP: {sbp}, HR: {hr}, Temp: {temp}¬∞C, AVPU: {avpu}\n",
                "NEWS2 total score:\"\"\"\n",
                "\n",
                "def extract_number(text):\n",
                "    \"\"\"Extract first number from text\"\"\"\n",
                "    match = re.search(r'\\b(\\d+)\\b', str(text))\n",
                "    return int(match.group(1)) if match else -1\n",
                "\n",
                "def query_nursesim(t):\n",
                "    if not nursesim_client:\n",
                "        return -1\n",
                "    try:\n",
                "        prompt = f\"Calculate NEWS2: RR={t.rr}, SpO2={t.spo2}%, O2={'Yes' if t.o2 else 'No'}, SBP={t.sbp}, HR={t.hr}, Temp={t.temp}, AVPU={t.avpu}. Return ONLY the total score.\"\n",
                "        result = nursesim_client.predict(prompt, api_name=\"/chat\")\n",
                "        return extract_number(result)\n",
                "    except Exception as e:\n",
                "        print(f\"   NurseSim error: {e}\")\n",
                "        return -1\n",
                "\n",
                "def query_gemini(t):\n",
                "    if not gemini_model:\n",
                "        return -1\n",
                "    try:\n",
                "        prompt = NEWS2_PROMPT.format(rr=t.rr, spo2=t.spo2, o2='Yes' if t.o2 else 'No', sbp=t.sbp, hr=t.hr, temp=t.temp, avpu=t.avpu)\n",
                "        result = gemini_model.generate_content(prompt)\n",
                "        return extract_number(result.text)\n",
                "    except:\n",
                "        return -1\n",
                "\n",
                "def query_gpt(t):\n",
                "    try:\n",
                "        prompt = NEWS2_PROMPT.format(rr=t.rr, spo2=t.spo2, o2='Yes' if t.o2 else 'No', sbp=t.sbp, hr=t.hr, temp=t.temp, avpu=t.avpu)\n",
                "        resp = gpt_client.chat.completions.create(\n",
                "            model=\"gpt-4o\",\n",
                "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
                "            max_tokens=50\n",
                "        )\n",
                "        return extract_number(resp.choices[0].message.content)\n",
                "    except:\n",
                "        return -1\n",
                "\n",
                "print(\"‚úÖ Query functions ready\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üî¨ Run Benchmark"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"üî¨ Running NEWS2 Benchmark...\\n\")\n",
                "results = []\n",
                "\n",
                "for t in TESTS:\n",
                "    print(f\"{t.id}: Expected={t.expected}\", end=\" \")\n",
                "    \n",
                "    # Query all models\n",
                "    ns = query_nursesim(t)\n",
                "    gm = query_gemini(t)\n",
                "    gp = query_gpt(t)\n",
                "    \n",
                "    print(f\"| NurseSim={ns} | Gemini={gm} | GPT={gp}\")\n",
                "    \n",
                "    results.append({\n",
                "        'case': t.id,\n",
                "        'expected': t.expected,\n",
                "        'nursesim': ns,\n",
                "        'gemini': gm,\n",
                "        'gpt': gp,\n",
                "        'ns_correct': ns == t.expected,\n",
                "        'gm_correct': gm == t.expected,\n",
                "        'gp_correct': gp == t.expected,\n",
                "    })\n",
                "    time.sleep(0.5)\n",
                "\n",
                "df = pd.DataFrame(results)\n",
                "print(\"\\n‚úÖ Benchmark complete!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Results\n",
                "print(\"\\nüìä NEWS2 CALCULATION ACCURACY\")\n",
                "print(\"=\" * 50)\n",
                "\n",
                "models = [\n",
                "    ('NurseSim-Triage', 'ns_correct', 'nursesim'),\n",
                "    (gemini_name or 'Gemini', 'gm_correct', 'gemini'),\n",
                "    ('GPT-4o', 'gp_correct', 'gpt')\n",
                "]\n",
                "\n",
                "summary = {}\n",
                "for name, col, pred_col in models:\n",
                "    valid = df[df[pred_col] >= 0]  # Exclude errors\n",
                "    if len(valid) > 0:\n",
                "        accuracy = valid[col].mean() * 100\n",
                "        mae = abs(valid['expected'] - valid[pred_col]).mean()\n",
                "        summary[name] = {'accuracy': accuracy, 'mae': mae, 'n': len(valid)}\n",
                "        print(f\"\\n{name}:\")\n",
                "        print(f\"  Exact Match: {valid[col].sum()}/{len(valid)} ({accuracy:.1f}%)\")\n",
                "        print(f\"  Mean Abs Error: {mae:.2f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualization\n",
                "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
                "\n",
                "# Accuracy comparison\n",
                "ax1 = axes[0]\n",
                "names = list(summary.keys())\n",
                "accs = [summary[n]['accuracy'] for n in names]\n",
                "colors = ['#ef4444', '#10b981', '#3b82f6']  # Red for NurseSim, Green Gemini, Blue GPT\n",
                "bars = ax1.bar(names, accs, color=colors[:len(names)])\n",
                "ax1.set_ylabel('Accuracy %')\n",
                "ax1.set_title('NEWS2 Calculation Accuracy')\n",
                "ax1.set_ylim(0, 100)\n",
                "for bar, val in zip(bars, accs):\n",
                "    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 2, f'{val:.0f}%', ha='center', fontweight='bold')\n",
                "\n",
                "# MAE comparison\n",
                "ax2 = axes[1]\n",
                "maes = [summary[n]['mae'] for n in names]\n",
                "bars2 = ax2.bar(names, maes, color=colors[:len(names)])\n",
                "ax2.set_ylabel('Mean Absolute Error')\n",
                "ax2.set_title('NEWS2 Calculation Error (lower is better)')\n",
                "for bar, val in zip(bars2, maes):\n",
                "    ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1, f'{val:.2f}', ha='center', fontweight='bold')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('news2_model_comparison.png', dpi=150)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Detailed results table\n",
                "print(\"\\nüìã Detailed Results\")\n",
                "print(df[['case', 'expected', 'nursesim', 'gemini', 'gpt']].to_string(index=False))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generate Report\n",
                "from datetime import datetime\n",
                "\n",
                "winner = max(summary.keys(), key=lambda x: summary[x]['accuracy'])\n",
                "\n",
                "report = f\"\"\"# NEWS2 Calculation Benchmark Report\n",
                "**Generated**: {datetime.now().strftime('%Y-%m-%d %H:%M')}\n",
                "\n",
                "## Summary\n",
                "\n",
                "| Model | Accuracy | Mean Abs Error |\n",
                "|-------|----------|----------------|\n",
                "\"\"\"\n",
                "for name in summary:\n",
                "    star = \"‚≠ê\" if name == winner else \"\"\n",
                "    report += f\"| {name} {star} | {summary[name]['accuracy']:.1f}% | {summary[name]['mae']:.2f} |\\n\"\n",
                "\n",
                "report += f\"\"\"\n",
                "**Winner**: {winner} with {summary[winner]['accuracy']:.1f}% accuracy\n",
                "\n",
                "## Detailed Results\n",
                "\n",
                "| Case | Expected | NurseSim | Gemini | GPT |\n",
                "|------|----------|----------|--------|-----|\n",
                "\"\"\"\n",
                "for _, row in df.iterrows():\n",
                "    ns = \"‚úÖ\" if row['ns_correct'] else str(row['nursesim'])\n",
                "    gm = \"‚úÖ\" if row['gm_correct'] else str(row['gemini'])\n",
                "    gp = \"‚úÖ\" if row['gp_correct'] else str(row['gpt'])\n",
                "    report += f\"| {row['case']} | {row['expected']} | {ns} | {gm} | {gp} |\\n\"\n",
                "\n",
                "report += \"\\n---\\n*NurseSim-Triage NEWS2 Benchmark | practicedev.cloud*\"\n",
                "\n",
                "print(report)\n",
                "with open('news2_comparison_report.md', 'w') as f:\n",
                "    f.write(report)\n",
                "print(\"\\n‚úÖ Saved: news2_comparison_report.md\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df.to_csv('news2_comparison_results.csv', index=False)\n",
                "print(\"‚úÖ Saved: news2_comparison_results.csv\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}